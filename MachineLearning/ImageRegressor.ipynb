{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a025491e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([119000, 119000, 119000, 119000, 119000, 119000, 119000, 119000, 119000,\n",
      "        119000, 119000])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class ApartmentDatasetPyTorch(Dataset):\n",
    "    def __init__(self, data_dir, images_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data_dir = data_dir\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.df = pd.read_csv(data_dir)\n",
    "        self.df.id = self.df.id.astype(str)\n",
    "        \n",
    "        for subdir, dirs, files in os.walk(images_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(\".jpg\") or file.endswith(\".JPG\") or file.endswith(\".jpeg\"):\n",
    "                    img_path = os.path.join(subdir, file)\n",
    "                    if os.path.getsize(img_path) > 0:\n",
    "                        self.image_paths.append(img_path)\n",
    "                    \n",
    "        self.error_log = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "        except:\n",
    "            self.error_log[idx] = \"cant load\"\n",
    "            return None\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        price = self.__get_price_from_image_path(image_path)\n",
    "        return image, price\n",
    "    \n",
    "    def __get_price_from_image_path(self, image_path):\n",
    "        components = image_path.split(\"/\")\n",
    "        source = components[2]\n",
    "        ap_native_id = components[3]\n",
    "        filtered_rows = self.df[(self.df[\"source\"] == source) & (self.df[\"id\"] == ap_native_id)]\n",
    "        price = int(filtered_rows[\"price\"])\n",
    "        return price\n",
    "\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images to 128x128\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "dataset = ApartmentDatasetPyTorch(\n",
    "    data_dir = \"../apartments.csv\",\n",
    "    images_dir = '../images', \n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Now you can use the dataloader in your training loop\n",
    "for image, price in dataloader:\n",
    "    # Your training code here\n",
    "    print(price)  # Should print torch.Size([32, 3, 128, 128]) for batches of 32 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1d1cc520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class ApartmentDatasetTensorFlow:\n",
    "    def __init__(self, data_dir, images_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.images_dir = images_dir\n",
    "        self.image_paths = []\n",
    "        self.df = pd.read_csv(data_dir)\n",
    "        self.df.id = self.df.id.astype(str)\n",
    "        \n",
    "        for subdir, dirs, files in os.walk(images_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(\".jpg\") or file.endswith(\".JPG\") or file.endswith(\".jpeg\"):\n",
    "                    img_path = os.path.join(subdir, file)\n",
    "                    if os.path.getsize(img_path) > 0:\n",
    "                        self.image_paths.append(img_path)\n",
    "                    \n",
    "        self.error_log = {}\n",
    "        self.length = len(self.image_paths)\n",
    "\n",
    "    def generator(self):\n",
    "        for img_path in self.image_paths:\n",
    "            try:\n",
    "                image = Image.open(img_path)\n",
    "                image = image.resize((224, 224))\n",
    "                image = np.array(image, dtype=np.float32) / 255.0\n",
    "            except Exception as e:\n",
    "                self.error_log[img_path] = str(e)\n",
    "                continue\n",
    "            \n",
    "            price = self.__get_price_from_image_path(img_path)\n",
    "            yield image, price\n",
    "    \n",
    "    def __get_price_from_image_path(self, image_path):\n",
    "        components = image_path.split(\"/\")\n",
    "        source = components[-3]\n",
    "        ap_native_id = components[-2]\n",
    "        filtered_rows = self.df[(self.df[\"source\"] == source) & (self.df[\"id\"] == ap_native_id)]\n",
    "        price = int(filtered_rows.iloc[0][\"price\"])\n",
    "        return price\n",
    "\n",
    "    def get_tf_dataset(self):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            self.generator,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "dataset = ApartmentDatasetTensorFlow(\n",
    "    data_dir = \"../apartments.csv\",\n",
    "    images_dir = '../images'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "75dbf9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(119000.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = dataset.get_tf_dataset()\n",
    "for t1, t2 in tf_dataset.take(1):\n",
    "    print(t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662cb141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
