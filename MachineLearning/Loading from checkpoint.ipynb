{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5717565",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d2659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"data_dir\" : \"../data/myrealty_apartments.csv\",\n",
    "    \"images_dir\" : '../images/myrealty',\n",
    "    \"img_input_size\" : 128,\n",
    "    \"batch_size\" : 32,\n",
    "    \"shuffle\" : True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7991e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from ApartmentsDatasetPyTorch import ApartmentsDatasetPyTorch\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((params[\"img_input_size\"], params[\"img_input_size\"])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "dataset = ApartmentsDatasetPyTorch(\n",
    "    data_dir = params[\"data_dir\"],\n",
    "    images_dir = params[\"images_dir\"], \n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = params[\"batch_size\"],\n",
    "    shuffle = params[\"shuffle\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96b653c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "# Load the pretrained model\n",
    "model = timm.create_model('inception_v4', pretrained=True)\n",
    "\n",
    "# Freeze all the layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "new_classifier = nn.Sequential(\n",
    "    model.last_linear,\n",
    "    nn.Linear(1000, 512), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 1)\n",
    ")\n",
    "\n",
    "# Replace the existing classifier in the model\n",
    "model.last_linear = new_classifier\n",
    "\n",
    "# Model training setup\n",
    "model.train()  # Switch to training mode\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Example optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # Mean Squared Error Loss for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd9193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss 77638590464.0\n",
      "Running loss 183537672192.0\n",
      "Running loss 286878244864.0\n",
      "Running loss 376360951808.0\n",
      "Running loss 437717114880.0\n",
      "Running loss 493274865664.0\n",
      "Running loss 576043671552.0\n",
      "Running loss 643890479104.0\n",
      "Running loss 761104064512.0\n",
      "Running loss 814176972800.0\n",
      "Running loss 882692370432.0\n",
      "Running loss 915114801152.0\n",
      "Running loss 993028814848.0\n",
      "Running loss 1108766963712.0\n",
      "Running loss 1191024285696.0\n",
      "Running loss 1233064708096.0\n",
      "Running loss 1263161223168.0\n",
      "Running loss 1322509662208.0\n",
      "Running loss 1375635171328.0\n",
      "Running loss 1438308513792.0\n",
      "Running loss 1488880588800.0\n",
      "Running loss 1541074647040.0\n",
      "Running loss 1606322272256.0\n",
      "Epoch 1, Loss: 69840098793.73914\n",
      "Running loss 25482844160.0\n",
      "Running loss 45880471552.0\n",
      "Running loss 80556224512.0\n",
      "Running loss 132124053504.0\n",
      "Running loss 172521992192.0\n",
      "Running loss 220942479360.0\n",
      "Running loss 280922075136.0\n",
      "Running loss 342895861760.0\n",
      "Running loss 386859941888.0\n",
      "Running loss 466572296192.0\n",
      "Running loss 495193931776.0\n",
      "Running loss 545501855744.0\n",
      "Running loss 614753042432.0\n",
      "Running loss 663755345920.0\n",
      "Running loss 727285923840.0\n",
      "Running loss 760784433152.0\n",
      "Running loss 834051903488.0\n",
      "Running loss 903026864128.0\n",
      "Running loss 961160085504.0\n",
      "Running loss 996910186496.0\n",
      "Running loss 1027336466432.0\n",
      "Running loss 1059415115776.0\n",
      "Running loss 1072304872448.0\n",
      "Epoch 2, Loss: 46621950976.0\n",
      "Running loss 65273065472.0\n",
      "Running loss 125599346688.0\n",
      "Running loss 164398055424.0\n",
      "Running loss 194556442624.0\n",
      "Running loss 220382935040.0\n",
      "Running loss 273572288512.0\n",
      "Running loss 290414442496.0\n",
      "Running loss 339111729152.0\n",
      "Running loss 368902643712.0\n",
      "Running loss 414540394496.0\n",
      "Running loss 490399084544.0\n",
      "Running loss 528636063744.0\n",
      "Running loss 574985863168.0\n",
      "Running loss 592591497216.0\n",
      "Running loss 642825713664.0\n",
      "Running loss 656801862656.0\n",
      "Running loss 698502190080.0\n",
      "Running loss 718375216128.0\n",
      "Running loss 757041075200.0\n",
      "Running loss 788257248256.0\n",
      "Running loss 818595515392.0\n",
      "Running loss 837485294592.0\n",
      "Running loss 874850300928.0\n",
      "Epoch 3, Loss: 38036969605.565216\n",
      "Running loss 22951370752.0\n",
      "Running loss 36126840832.0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "# Define loss function and optimizer\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, prices = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, prices.view(-1, 1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print(\"Running loss\", running_loss)\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dac8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
