{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd51b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import sys\n",
    "import logging\n",
    "from logging import Logger\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.8f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0906f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_places = { \n",
    "    \"opera\" : (40.18600,44.51509),\n",
    "    \"malibu\" : (40.18306,44.50799),\n",
    "    \"aua\" : (40.19243,44.50446),\n",
    "    \"zvartnoc\" : (40.1523,44.4005)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7e7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have two datasets that have addresses and one that has coordinates. \n",
    "# We need coordinates. \n",
    "# We will write a service that converts an address to a coordinate. Then,\n",
    "# We will write a service that uses coordinates to geocode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a856e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_address(address):\n",
    "    s = address\n",
    "    splits = s.split(\", \")\n",
    "    split_count = len(splits)\n",
    "    if split_count >= 3:\n",
    "        s = splits[-1]\n",
    "\n",
    "    for key, value in myrealty_mapping.items():\n",
    "        s = s.replace(key, value)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b913636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "class AddressToCoordinateConverter:\n",
    "    \n",
    "    def __init__(self, streets_csv_path):\n",
    "        self.streets = pd.read_csv(streets_csv_path)\n",
    "    \n",
    "    def convert(self, address):\n",
    "        return self.get_top_matched_coordinate(df = self.streets, query = address)\n",
    "    \n",
    "    def get_top_matched_coordinate(self, df, query, debug = False):\n",
    "        max_score = 0\n",
    "        top_row = None\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            score = fuzz.ratio(query.lower(), row['name_en'].lower())\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                top_row = row\n",
    "\n",
    "        if debug:\n",
    "            return top_row\n",
    "        else:\n",
    "            # because it is a string when we read it from streets.csv\n",
    "            return self.convert_to_tuple(top_row[\"coordinates\"])\n",
    "        \n",
    "    def convert_to_tuple(self, cell):\n",
    "        try:\n",
    "            # Use ast.literal_eval to safely evaluate the string\n",
    "            return ast.literal_eval(cell)\n",
    "        except (ValueError, SyntaxError):\n",
    "            # Handle the case where the cell is not a valid tuple string\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8f5c5b",
   "metadata": {},
   "source": [
    "# Converting physical address into coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d25e5b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LONG RUN\n",
    "myrealty = pd.read_csv(\"../data/myrealty_apartments.csv\")\n",
    "myrealty['location'] = myrealty['location'].apply(format_address)\n",
    "converter = AddressToCoordinateConverter(\"streets.csv\")\n",
    "myrealty[\"coordinates\"] = myrealty[\"location\"].apply(converter.convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff96495",
   "metadata": {},
   "source": [
    "# Extracting distances to significant locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e16ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Services import GeoService\n",
    "\n",
    "class MapFeatureAggregator:\n",
    "    \n",
    "    def __init__(self, geo_service: GeoService):\n",
    "        self.geo_service = geo_service\n",
    "    \n",
    "    def significant_distances(self, data, location_col: str):\n",
    "        all_distances = []\n",
    "        locations = data[location_col]\n",
    "        for coordinate in locations:\n",
    "            distances = self.geo_service.distance_to_significant(coordinate)\n",
    "            all_distances.append(distances)\n",
    "            \n",
    "        df = pd.DataFrame(all_distances) \n",
    "        return df\n",
    "    \n",
    "    def amenities_count(self, data, location_col: str):\n",
    "        aggregated_amentities_count = pd.DataFrame()\n",
    "        locations = data[location_col]\n",
    "        for coordinate in locations:\n",
    "            amenities_df = self.geo_service.get_amenities_from_point(coordinate)\n",
    "            dict_to_add = amenities_df[\"amenity\"].value_counts().to_dict()\n",
    "            aggregated_amentities_count = add_row_from_dict_with_zeros(\n",
    "                aggregated_amentities_count,\n",
    "                dict_to_add\n",
    "            )\n",
    "        return aggregated_amentities_count\n",
    "    \n",
    "    def add_row_from_dict_with_zeros(self, df, data_dict):\n",
    "        \"\"\"\n",
    "        Adds a row to the dataframe from a dictionary. New columns are added if they don't exist, \n",
    "        and are prepended with 'L' if they are new. Missing values are filled with 0.\n",
    "\n",
    "        Args:\n",
    "        df (pd.DataFrame): The dataframe to add the row to.\n",
    "        data_dict (dict): The dictionary containing the data to add.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: The updated dataframe.\n",
    "        \"\"\"\n",
    "        # Prepend 'L' to new columns\n",
    "        new_columns = {key: 'L_' + key if key not in df.columns else key for key in data_dict.keys()}\n",
    "        updated_dict = {new_columns[key]: value for key, value in data_dict.items()}\n",
    "\n",
    "        # Add missing columns to the dataframe with 0 values\n",
    "        for col in new_columns.values():\n",
    "            if col not in df.columns:\n",
    "                df[col] = 0\n",
    "\n",
    "        # Replace NaN in the dictionary with 0 for existing columns\n",
    "        for col in df.columns:\n",
    "            if col not in updated_dict:\n",
    "                updated_dict[col] = 0\n",
    "\n",
    "        # Add the new row\n",
    "        new_row = pd.DataFrame([updated_dict], columns=df.columns)\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fdf04ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_service = GeoService(\n",
    "    significant_places,\n",
    "    radius = 300\n",
    ")\n",
    "featurer = ApartmentGeoServiceFeaturer(geo_service)\n",
    "significant_distances = featurer.significant_distances(myrealty, \"coordinates\")\n",
    "amenities = featurer.amenities_count(myrealty, \"coordinates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10f561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
